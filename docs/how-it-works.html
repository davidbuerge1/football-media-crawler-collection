<!doctype html>
<html lang="de">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Wie der Crawler funktioniert</title>
    <link rel="stylesheet" href="style.css?v=3" />
  </head>
  <body>
    <main class="content">
      <div class="topbar">
        <div class="left">
          <a class="btn btn-ghost" href="index.html">Zurueck</a>
          <span class="brand">Crawler</span>
        </div>
      </div>

      <h1>Wie der Crawler funktioniert</h1>
      <p class="muted">Kurz und verstaendlich erklaert.</p>
      <p>Der Crawler verwendet die Sitemap einer Website als Einstiegspunkt, um alle relevanten Fussball-Artikel zu finden. Danach werden die Links gespeichert und pro Jahr ausgewertet.</p>
      <p>Beispiel fuer eine Artikel-Sitemap (Spiegel): https://www.spiegel.de/sitemaps/article/sitemap-2019-05_66.xml</p>
      <ul>
        <li>Er laedt die Sitemap(s) der Website und liest die URLs aus.</li>
        <li>Er filtert Fussball-Seiten mit den gleichen URL-Regeln wie die Klassifikation (Ligen, eindeutige Namen, Ausschluss-Begriffe).</li>
        <li>Er speichert alle gefundenen Links in einer URLs-CSV.</li>
        <li>Er zaehlt pro Jahr Frauen- und Herrenfussball.</li>
        <li>Er schreibt die Auswertung in eine Counts-CSV.</li>
      </ul>
      <h2>Klassifikation</h2>
      <p>Die Zuordnung erfolgt ueber einen URL-Algorithmus mit Ligen-Schluesselwoertern und eindeutigen Spielerinnen-Namen. Begriffe wie "spielerfrau" oder "moglie" werden als Ausschluss verwendet, damit Artikel ueber Spieler-Familien nicht als Frauenfussball zaehlen. Der gleiche Regelsatz wird bereits beim Filtern angewendet.</p>

      <h2>Beispiel-Script (Spiegel)</h2>
      <pre><code># stark vereinfacht: URLs werden ueber Tokens gefiltert und klassifiziert
def tokenize(url: str) -&gt; set[str]:
    lower = url.lower()
    cleaned = re.sub(r"[^a-z0-9]+", " ", lower)
    return set(t for t in cleaned.split() if t)

def matches_rules(url: str) -&gt; bool:
    tokens = tokenize(url)
    return bool(tokens &amp; (WOMEN_TOKENS | MEN_TOKENS | EXCLUDE_FRAU))

for loc, lastmod in sitemap_entries:
    if not matches_rules(loc):
        continue
    category = classify_url(loc, "Spiegel")
    # URL in CSV schreiben + pro Jahr zaehlen</code></pre>
    </main>
  </body>
</html>
