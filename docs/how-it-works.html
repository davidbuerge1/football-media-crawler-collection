<!doctype html>
<html lang="de">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Wie der Crawler funktioniert</title>
    <link rel="stylesheet" href="style.css?v=3" />
  </head>
  <body>
    <main class="content">
      <div class="topbar">
        <div class="left">
          <a class="btn btn-ghost" href="index.html">Zur?ck</a>
          <span class="brand">Crawler</span>
        </div>
      </div>

      <h1>Wie der Crawler funktioniert</h1>
      <p class="muted">Kurz und verst?ndlich erkl?rt.</p>
      <p>Der Crawler verwendet die Sitemap einer Website als Einstiegspunkt, um alle relevanten Fussball-Artikel zu finden. Danach werden die Links gespeichert und pro Jahr ausgewertet.</p>
      <p>Beispiel f?r eine Artikel-Sitemap (Spiegel): https://www.spiegel.de/sitemaps/article/sitemap-2019-05_66.xml</p>
      <ul>
        <li>Er l?dt die Sitemap(s) der Website und liest die URLs aus.</li>
        <li>Er filtert Fussball-Seiten anhand der URL-Struktur.</li>
        <li>Er speichert alle gefundenen Links in einer URLs-CSV.</li>
        <li>Er z?hlt pro Jahr Frauen- und Herrenfussball.</li>
        <li>Er schreibt die Auswertung in eine Counts-CSV.</li>
      </ul>
      <h2>Klassifikation</h2>
      <p>Die Zuordnung erfolgt ?ber einen URL-Algorithmus mit Ligen-Schl?sselw?rtern und eindeutigen Spielerinnen-Namen. Begriffe wie "spielerfrau" oder "moglie" werden ausgeschlossen.</p>

      <h2>Beispiel-Script (Spiegel)</h2>
      <pre><code>import re
import time
import csv
import requests
import xml.etree.ElementTree as ET

# --- Einstellungen ---
START_YEAR = 2005
END_YEAR = 2025
SITEMAP_TEMPLATE = "https://www.example.com/sitemaps/articles/{year}_{month:02d}.xml"
FOOTBALL_PREFIX = "https://www.example.com/sport/fussball/"

EXCLUDE_FRAU = {"spielerfrau", "ehefrau", "moglie"}
WOMEN_TOKENS = {"frauen", "frauenfussball", "wsl"}
MEN_TOKENS = {"bundesliga", "champions-league"}

def tokenize(url: str) -> set[str]:
    lower = url.lower()
    cleaned = re.sub(r"[^a-z0-9]+", " ", lower)
    return set(t for t in cleaned.split() if t)

def matches_rules(url: str) -> bool:
    tokens = tokenize(url)
    return bool(tokens & (WOMEN_TOKENS | MEN_TOKENS | EXCLUDE_FRAU))

def fetch_sitemap(year: int, month: int) -> str:
    url = SITEMAP_TEMPLATE.format(year=year, month=month)
    r = requests.get(url, timeout=30)
    r.raise_for_status()
    return r.text

def parse_sitemap(xml_text: str):
    ns = {"sm": "http://www.sitemaps.org/schemas/sitemap/0.9"}
    root = ET.fromstring(xml_text)
    out = []
    for url_el in root.findall("sm:url", ns):
        loc_el = url_el.find("sm:loc", ns)
        lastmod_el = url_el.find("sm:lastmod", ns)
        if loc_el is None:
            continue
        loc = loc_el.text.strip()
        lastmod = lastmod_el.text.strip() if lastmod_el is not None and lastmod_el.text else ""
        out.append((loc, lastmod))
    return out

rows = []
for year in range(START_YEAR, END_YEAR + 1):
    for month in range(1, 13):
        try:
            xml_text = fetch_sitemap(year, month)
            entries = parse_sitemap(xml_text)
        except Exception:
            continue
        for loc, lastmod in entries:
            if not loc.startswith(FOOTBALL_PREFIX):
                continue
            if not matches_rules(loc):
                continue
            rows.append({"year": year, "month": month, "lastmod": lastmod, "url": loc})
        time.sleep(0.8)

# CSV schreiben und pro Jahr auswerten</code></pre>
    </main>
  </body>
</html>
